{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG_vggface_extraction.ipynb","provenance":[],"authorship_tag":"ABX9TyO1vA56BV45Wv7gU3ATNO8y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ngmy-R4vBAJU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1594045551170,"user_tz":-120,"elapsed":11655,"user":{"displayName":"auzil henzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy9gWIfStXIvv6xs4veguwpupoHbg8EKsSsTU4=s64","userId":"00075401785580697171"}},"outputId":"9fa7746c-c64c-40f2-ad2f-c838303c5b69"},"source":["!pip install torchfile\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision\n","from torchvision import transforms\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","from PIL import Image\n","import pandas as pd\n","import torchfile\n","\n","# from facenet_pytorch import InceptionResnetV1, fixed_image_standardization, training\n","# a = []\n","# while(1):\n","#     a.append(1)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting torchfile\n","  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n","Building wheels for collected packages: torchfile\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5712 sha256=998bef54b6b16834773c006101a1228c49b9c45f9e93084026a743b2dc854514\n","  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n","Successfully built torchfile\n","Installing collected packages: torchfile\n","Successfully installed torchfile-0.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-DVjEZuBBfri","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594045568179,"user_tz":-120,"elapsed":28650,"user":{"displayName":"auzil henzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy9gWIfStXIvv6xs4veguwpupoHbg8EKsSsTU4=s64","userId":"00075401785580697171"}},"outputId":"f9a015f0-74c5-45d3-bfe6-c10420a895d0"},"source":["from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cKRvV-P-BhDb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594045587530,"user_tz":-120,"elapsed":17774,"user":{"displayName":"auzil henzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy9gWIfStXIvv6xs4veguwpupoHbg8EKsSsTU4=s64","userId":"00075401785580697171"}},"outputId":"2c49ed61-0608-4532-dc91-74146540252a"},"source":["%%time\n","zip_path = '/content/drive/My Drive/Colab Notebooks/allimgs_face2.zip'\n","!cp \"{zip_path}\" .\n","!unzip -q allimgs_face2.zip \n","!rm allimgs_face2.zip"],"execution_count":3,"outputs":[{"output_type":"stream","text":["CPU times: user 51.7 ms, sys: 26.5 ms, total: 78.2 ms\n","Wall time: 16.5 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XOOHtFgegMLj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594045591824,"user_tz":-120,"elapsed":2110,"user":{"displayName":"auzil henzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy9gWIfStXIvv6xs4veguwpupoHbg8EKsSsTU4=s64","userId":"00075401785580697171"}}},"source":["# # Get train and test data for classification\n","train_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train_on_cand.csv')\n","new_paths = []\n","for path, winner in zip(train_df[train_df.columns[2]].tolist(), train_df[train_df.columns[3]].tolist()):\n","    words = path.split('/')\n","    new_path = 'allimgs_face/'+words[1]+'/'+words[2]\n","    if '.webp' not in new_path:\n","        new_paths.append([new_path, winner])\n","train_df = pd.DataFrame(new_paths) \n","train_df[train_df.columns[1]]= train_df[train_df.columns[1]].astype(float)\n","# train_df = train_df.sample(frac=1).reset_index(drop=True)\n","\n","\n","test_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/test_on_cand.csv')\n","new_paths_test = []\n","for path, winner in zip(test_df[test_df.columns[2]].tolist(), test_df[test_df.columns[3]].tolist()):\n","    words = path.split('/')\n","    new_path = 'allimgs_face/'+words[1]+'/'+words[2]\n","    if '.webp' not in new_path:\n","        new_paths_test.append([new_path, winner])\n","\n","test_df = pd.DataFrame(new_paths_test)    \n","test_df[test_df.columns[1]]= test_df[test_df.columns[1]].astype(float)   \n","\n","val_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/val_on_cand.csv')\n","new_paths_val = []\n","for path, winner in zip(val_df[val_df.columns[2]].tolist(), val_df[val_df.columns[3]].tolist()):\n","    words = path.split('/')\n","    new_path = 'allimgs_face/'+words[1]+'/'+words[2]\n","    if '.webp' not in new_path:\n","        new_paths_val.append([new_path, winner])\n","\n","\n","val_df = pd.DataFrame(new_paths_val)    \n","val_df[val_df.columns[1]]= val_df[val_df.columns[1]].astype(float)   \n","# val_df"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"_t20W0-9Bycg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594045597374,"user_tz":-120,"elapsed":533,"user":{"displayName":"auzil henzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy9gWIfStXIvv6xs4veguwpupoHbg8EKsSsTU4=s64","userId":"00075401785580697171"}}},"source":["# Create a dataloader class\n","class DatasetFaces_Rank(Dataset):\n","    \n","    def __init__(self, df, transform=None):\n","        self.data = df\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, index):\n","\n","        img_name = self.data[self.data.columns[0]].iloc[index]\n","        # img_name = img_name.split('/')\n","\n","   \n","\n","        image = Image.open(\"/content/\"+img_name).convert('RGB')\n","        # label = self.data[self.data.columns[1]].iloc[index]\n","        if self.transform is not None:\n","            image = self.transform(image)\n","        else:\n","            print(\"TRANSFORM FAILED\")\n","        return image\n","  \n","# Create a dataloader class\n","class DatasetFaces_classify(Dataset):\n","    \n","    def __init__(self, df, transform=None):\n","        self.data = df\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, index):\n","\n","        img_name = self.data[self.data.columns[0]].iloc[index]\n","        # img_name = img_name.split('/')\n","\n","   \n","\n","        image = Image.open(\"/content/\"+img_name).convert('RGB')\n","        label = self.data[self.data.columns[1]].iloc[index]\n","        if self.transform is not None:\n","            image = self.transform(image)\n","        else:\n","            print(\"TRANSFORM FAILED\")\n","        return image,label"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ps3z77nzCAZG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594045604611,"user_tz":-120,"elapsed":498,"user":{"displayName":"auzil henzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy9gWIfStXIvv6xs4veguwpupoHbg8EKsSsTU4=s64","userId":"00075401785580697171"}}},"source":["# Create a transform for data prep\n","transform = transforms.Compose([\n","        transforms.Resize((224,224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([123.68, 116.78, 103.94], [1, 1, 1]),\n","    ])\n","# Classification\n","train_dataset = DatasetFaces_classify(train_df, transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1,shuffle=False, num_workers=1)\n","\n","test_dataset = DatasetFaces_classify(test_df, transform)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1,shuffle=False, num_workers=1)\n","\n","\n","val_dataset = DatasetFaces_classify(val_df, transform)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1,shuffle=False, num_workers=1)\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Q-dMIaFaNNp","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594045607286,"user_tz":-120,"elapsed":697,"user":{"displayName":"auzil henzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy9gWIfStXIvv6xs4veguwpupoHbg8EKsSsTU4=s64","userId":"00075401785580697171"}}},"source":["class VGG_16(nn.Module):\n","    \"\"\"\n","    Main Class\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"\n","        Constructor\n","        \"\"\"\n","        super().__init__()\n","        self.block_size = [2, 2, 3, 3, 3]\n","        self.conv_1_1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n","        self.conv_1_2 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n","        self.conv_2_1 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n","        self.conv_2_2 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n","        self.conv_3_1 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n","        self.conv_3_2 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n","        self.conv_3_3 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n","        self.conv_4_1 = nn.Conv2d(256, 512, 3, stride=1, padding=1)\n","        self.conv_4_2 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n","        self.conv_4_3 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n","        self.conv_5_1 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n","        self.conv_5_2 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n","        self.conv_5_3 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n","        self.fc6 = nn.Linear(512 * 7 * 7, 4096)\n","        self.fc7 = nn.Linear(4096, 4096)\n","        self.fc8 = nn.Linear(4096, 2622)\n","\n","    def load_weights(self, path=\"/content/drive/My Drive/Colab Notebooks/VGG_FACE.t7\"):\n","        \"\"\" Function to load luatorch pretrained\n","        Args:\n","            path: path for the luatorch pretrained\n","        \"\"\"\n","        model = torchfile.load(path)\n","        counter = 1\n","        block = 1\n","        for i, layer in enumerate(model.modules):\n","            if layer.weight is not None:\n","                if block <= 5:\n","                    self_layer = getattr(self, \"conv_%d_%d\" % (block, counter))\n","                    counter += 1\n","                    if counter > self.block_size[block - 1]:\n","                        counter = 1\n","                        block += 1\n","                    self_layer.weight.data[...] = torch.tensor(layer.weight).view_as(self_layer.weight)[...]\n","                    self_layer.bias.data[...] = torch.tensor(layer.bias).view_as(self_layer.bias)[...]\n","                else:\n","                    self_layer = getattr(self, \"fc%d\" % (block))\n","                    block += 1\n","                    self_layer.weight.data[...] = torch.tensor(layer.weight).view_as(self_layer.weight)[...]\n","                    self_layer.bias.data[...] = torch.tensor(layer.bias).view_as(self_layer.bias)[...]\n","\n","    def forward(self, x):\n","        \"\"\" Pytorch forward\n","        Args:\n","            x: input image (224x224)\n","        Returns: class logits\n","        \"\"\"\n","        x = F.relu(self.conv_1_1(x))\n","        x = F.relu(self.conv_1_2(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = F.relu(self.conv_2_1(x))\n","        x = F.relu(self.conv_2_2(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = F.relu(self.conv_3_1(x))\n","        x = F.relu(self.conv_3_2(x))\n","        x = F.relu(self.conv_3_3(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = F.relu(self.conv_4_1(x))\n","        x = F.relu(self.conv_4_2(x))\n","        x = F.relu(self.conv_4_3(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x_5_1 = F.relu(self.conv_5_1(x))\n","        x_5_2 = F.relu(self.conv_5_2(x_5_1))\n","        x_5_3 = F.relu(self.conv_5_3(x_5_2))\n","        x = F.max_pool2d(x_5_3, 2, 2)\n","        x = x.view(x.size(0), -1)\n","        x = F.relu(self.fc6(x))\n","        x = F.dropout(x, 0.5, self.training)\n","        x = F.relu(self.fc7(x))\n","        x = F.dropout(x, 0.5, self.training)\n","        # return self.fc8(x)\n","        return(x_5_1, x_5_2,x_5_3)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fvns--nLCFZh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1594045669964,"user_tz":-120,"elapsed":18068,"user":{"displayName":"auzil henzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy9gWIfStXIvv6xs4veguwpupoHbg8EKsSsTU4=s64","userId":"00075401785580697171"}},"outputId":"51fa9105-c3af-43f1-807e-e0f74a96aae8"},"source":["# Load model and create model\n","model = VGG_16()\n","model.fc8 = nn.Linear(4096, 1)\n","weights = torch.load('/content/drive/My Drive/Colab Notebooks/model weights/vggface_vgg_3conv_best.pl')\n","model.load_state_dict(weights)\n","# model.Module\n","# model.load_weights()\n","print(model)\n","\n","if torch.cuda.is_available():\n","  print('using device: cuda')\n","else:\n","    print('using device: cpu')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","print(\"done\")\n","# print(feature_extractor)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["VGG_16(\n","  (conv_1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv_5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (fc6): Linear(in_features=25088, out_features=4096, bias=True)\n","  (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n","  (fc8): Linear(in_features=4096, out_features=1, bias=True)\n",")\n","using device: cuda\n","done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AbNwhxSaLHo4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594046286987,"user_tz":-120,"elapsed":330213,"user":{"displayName":"auzil henzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy9gWIfStXIvv6xs4veguwpupoHbg8EKsSsTU4=s64","userId":"00075401785580697171"}}},"source":["train_features = []\n","test_features = []\n","val_features = []\n","\n","with torch.no_grad():\n","        for data in train_loader:\n","            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","            inputs, label = data\n","            inputs = inputs.to(device)\n","            l25, l27, l29 = model(inputs)\n","            m = nn.MaxPool2d(14, stride=1)\n","            l29 = m(l29)\n","            l27 = m(l27)\n","            l25 = m(l25)\n","            train_features.append([l25.cpu().numpy(),l27.cpu().numpy(),l29.cpu().numpy(), label])\n","       \n","with torch.no_grad():\n","        for data in test_loader:\n","            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","            inputs, label = data\n","            inputs = inputs.to(device)\n","            l25, l27, l29 = model(inputs)\n","            m = nn.MaxPool2d(14, stride=1)\n","            l29 = m(l29)\n","            l27 = m(l27)\n","            l25 = m(l25)\n","            test_features.append([l25.cpu().numpy(),l27.cpu().numpy(),l29.cpu().numpy(), label])\n","with torch.no_grad():\n","        for data in val_loader:\n","            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","            inputs, label = data\n","            inputs = inputs.to(device)\n","            l25, l27, l29 = model(inputs)\n","            m = nn.MaxPool2d(14, stride=1)\n","            l29 = m(l29)\n","            l27 = m(l27)\n","            l25 = m(l25)\n","            val_features.append([l25.cpu().numpy(),l27.cpu().numpy(),l29.cpu().numpy(), label])\n","            \n","            \n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"S491qN-JLJpT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594046288697,"user_tz":-120,"elapsed":323348,"user":{"displayName":"auzil henzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy9gWIfStXIvv6xs4veguwpupoHbg8EKsSsTU4=s64","userId":"00075401785580697171"}},"outputId":"03de2ed1-e3cf-401a-8fb8-b8542d864673"},"source":["train_features = pd.DataFrame(train_features)\n","train_features.to_pickle('/content/drive/My Drive/Colab Notebooks/vgg16_vggface_features_train.pl')\n","test_features = pd.DataFrame(test_features)\n","test_features.to_pickle('/content/drive/My Drive/Colab Notebooks/vgg16_vggface_features_test.pl')\n","val_features = pd.DataFrame(val_features)\n","val_features.to_pickle('/content/drive/My Drive/Colab Notebooks/vgg16_vggface_features_val.pl')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n","  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-qU8ysHmLNV8","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}