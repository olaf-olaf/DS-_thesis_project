{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[[0.7136695]], [[0.5966748]], [[1.5684245]],...</td>\n",
       "      <td>[[[[0.2606857]], [[0.76252264]], [[0.]], [[0.8...</td>\n",
       "      <td>[[[[0.8388147]], [[1.1766884]], [[0.1948912]],...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[[0.87442553]], [[1.2025621]], [[0.8099077]]...</td>\n",
       "      <td>[[[[0.6031779]], [[0.954708]], [[0.00806442]],...</td>\n",
       "      <td>[[[[0.79707575]], [[1.1046199]], [[0.08605583]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[[0.91123986]], [[1.1268694]], [[1.5741594]]...</td>\n",
       "      <td>[[[[0.50245315]], [[0.8697139]], [[0.]], [[0.6...</td>\n",
       "      <td>[[[[0.6785448]], [[1.2957569]], [[0.0453416]],...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[[1.1057353]], [[1.0990793]], [[1.2561587]],...</td>\n",
       "      <td>[[[[0.31014588]], [[0.8029127]], [[0.]], [[0.7...</td>\n",
       "      <td>[[[[0.99477756]], [[1.0686543]], [[0.38822544]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[[0.3907119]], [[1.0809014]], [[1.4426181]],...</td>\n",
       "      <td>[[[[0.0794258]], [[0.92135847]], [[0.2039707]]...</td>\n",
       "      <td>[[[[0.7034851]], [[1.2801485]], [[0.2507491]],...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[[[0.99570894]], [[0.83248633]], [[1.4694465]...</td>\n",
       "      <td>[[[[0.24164061]], [[0.7189417]], [[0.]], [[0.9...</td>\n",
       "      <td>[[[[0.5510677]], [[1.0326794]], [[0.24347706]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[[[0.76090866]], [[0.66342896]], [[0.88885367...</td>\n",
       "      <td>[[[[0.13365938]], [[0.6038446]], [[0.]], [[1.0...</td>\n",
       "      <td>[[[[0.7100026]], [[1.1725931]], [[0.17521872]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[[[0.7673841]], [[1.0669808]], [[0.84954536]]...</td>\n",
       "      <td>[[[[0.1397689]], [[1.0670974]], [[0.]], [[0.78...</td>\n",
       "      <td>[[[[0.8027326]], [[1.1633745]], [[0.3125465]],...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[[[0.37856206]], [[0.6023888]], [[0.8931349]]...</td>\n",
       "      <td>[[[[0.12124376]], [[0.66590416]], [[0.]], [[0....</td>\n",
       "      <td>[[[[0.71915686]], [[1.2433087]], [[0.26504898]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[[[0.66082174]], [[0.90579623]], [[0.3597993]...</td>\n",
       "      <td>[[[[0.14087407]], [[0.82040477]], [[0.00061371...</td>\n",
       "      <td>[[[[1.0845159]], [[1.140809]], [[0.36609995]],...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[[[0.9646332]], [[1.3950489]], [[0.5280791]],...</td>\n",
       "      <td>[[[[0.6118944]], [[1.2479125]], [[0.01305945]]...</td>\n",
       "      <td>[[[[0.69267535]], [[1.6574126]], [[0.20235921]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[[[0.63429505]], [[1.4681506]], [[0.6332361]]...</td>\n",
       "      <td>[[[[0.33809397]], [[1.0178871]], [[0.]], [[1.1...</td>\n",
       "      <td>[[[[1.0219374]], [[1.7998372]], [[0.24411662]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[[[1.0837971]], [[0.7644463]], [[1.2890801]],...</td>\n",
       "      <td>[[[[0.10495465]], [[0.5524683]], [[0.]], [[0.7...</td>\n",
       "      <td>[[[[0.65444]], [[0.8391235]], [[0.2665369]], [...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[[[0.8955999]], [[0.95184493]], [[1.6119937]]...</td>\n",
       "      <td>[[[[0.7687045]], [[0.63126314]], [[0.02766945]...</td>\n",
       "      <td>[[[[1.2394602]], [[1.0608716]], [[0.19582509]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[[[[1.0990928]], [[0.70393604]], [[0.41227022]...</td>\n",
       "      <td>[[[[0.65635604]], [[0.62953955]], [[0.]], [[0....</td>\n",
       "      <td>[[[[0.86763823]], [[0.99151564]], [[0.2591284]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[[[0.6503165]], [[0.79853415]], [[0.73378366]...</td>\n",
       "      <td>[[[[0.2313944]], [[0.70172095]], [[0.]], [[0.7...</td>\n",
       "      <td>[[[[0.7999359]], [[1.3417534]], [[0.09992491]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[[[0.97953176]], [[0.8293885]], [[0.8897084]]...</td>\n",
       "      <td>[[[[0.48563817]], [[0.6013953]], [[0.00240682]...</td>\n",
       "      <td>[[[[0.94594485]], [[1.380919]], [[0.28708953]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[[[[0.9519514]], [[1.5046413]], [[1.5821965]],...</td>\n",
       "      <td>[[[[0.56910115]], [[1.4101962]], [[0.]], [[0.7...</td>\n",
       "      <td>[[[[0.5510655]], [[1.7857206]], [[0.34002197]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[[[[0.7706637]], [[0.7124087]], [[0.5919047]],...</td>\n",
       "      <td>[[[[0.5983701]], [[0.66026676]], [[0.00182363]...</td>\n",
       "      <td>[[[[1.1548083]], [[1.1908001]], [[0.21185969]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[[[[1.0570626]], [[0.92358977]], [[0.8314927]]...</td>\n",
       "      <td>[[[[0.87686324]], [[0.76871157]], [[0.]], [[1....</td>\n",
       "      <td>[[[[1.4832199]], [[1.252472]], [[0.2505346]], ...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[[[[0.46718642]], [[0.8464217]], [[0.6812674]]...</td>\n",
       "      <td>[[[[0.16215721]], [[0.7701032]], [[0.]], [[1.1...</td>\n",
       "      <td>[[[[1.0154465]], [[1.412256]], [[0.41162312]],...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[[[[1.1784594]], [[1.0386066]], [[0.51394343]]...</td>\n",
       "      <td>[[[[0.8511178]], [[0.8200752]], [[0.00610646]]...</td>\n",
       "      <td>[[[[0.9787493]], [[1.1150758]], [[0.02609569]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[[[[0.8702978]], [[0.43718627]], [[0.4393292]]...</td>\n",
       "      <td>[[[[0.7992814]], [[0.62536347]], [[0.02263787]...</td>\n",
       "      <td>[[[[1.3232431]], [[1.4357141]], [[0.21391706]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[[[[0.54999167]], [[0.98559886]], [[0.72847044...</td>\n",
       "      <td>[[[[0.32748532]], [[0.7007353]], [[0.]], [[0.7...</td>\n",
       "      <td>[[[[0.5517086]], [[1.2463572]], [[0.20973606]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[[[[0.72751796]], [[0.74342585]], [[1.6269205]...</td>\n",
       "      <td>[[[[0.37619206]], [[0.6912724]], [[0.]], [[0.8...</td>\n",
       "      <td>[[[[0.685026]], [[1.181264]], [[0.18105818]], ...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[[[[1.0140551]], [[0.9254571]], [[1.0211936]],...</td>\n",
       "      <td>[[[[0.89209735]], [[0.8156954]], [[0.12809315]...</td>\n",
       "      <td>[[[[1.2551823]], [[1.6936402]], [[0.14405799]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[[[[0.99596035]], [[0.6640087]], [[0.5937315]]...</td>\n",
       "      <td>[[[[0.48245692]], [[0.5905515]], [[0.]], [[1.0...</td>\n",
       "      <td>[[[[0.93079925]], [[1.2005582]], [[0.3911389]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[[[[0.55328953]], [[1.4391109]], [[0.9278571]]...</td>\n",
       "      <td>[[[[0.15273508]], [[0.9719503]], [[0.01391844]...</td>\n",
       "      <td>[[[[0.65038145]], [[1.5017123]], [[0.11106776]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[[[[1.6971041]], [[0.97803676]], [[1.2333802]]...</td>\n",
       "      <td>[[[[1.4583683]], [[0.88298976]], [[0.01492494]...</td>\n",
       "      <td>[[[[1.4840847]], [[1.3498926]], [[0.15299903]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[[[[0.68470556]], [[1.1094121]], [[1.0987729]]...</td>\n",
       "      <td>[[[[0.19278543]], [[1.1968535]], [[0.]], [[0.8...</td>\n",
       "      <td>[[[[0.62063473]], [[1.3134845]], [[0.19068573]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>[[[[1.0358715]], [[1.2295281]], [[0.9794683]],...</td>\n",
       "      <td>[[[[0.70956874]], [[0.977788]], [[0.00397338]]...</td>\n",
       "      <td>[[[[0.8566985]], [[1.7565303]], [[0.28917497]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>[[[[1.0349112]], [[0.75016]], [[1.5438305]], [...</td>\n",
       "      <td>[[[[0.64699465]], [[0.6856429]], [[0.14126514]...</td>\n",
       "      <td>[[[[0.9579328]], [[1.0833677]], [[0.1921882]],...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>[[[[1.2600394]], [[0.72507954]], [[0.8160462]]...</td>\n",
       "      <td>[[[[0.73059005]], [[0.6331663]], [[0.]], [[0.7...</td>\n",
       "      <td>[[[[0.6390508]], [[1.4283442]], [[0.17257033]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>[[[[0.5239251]], [[1.4076585]], [[0.6563418]],...</td>\n",
       "      <td>[[[[0.1708772]], [[0.7494808]], [[0.]], [[0.70...</td>\n",
       "      <td>[[[[0.98789376]], [[1.1657844]], [[0.3285892]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>[[[[0.96932584]], [[0.8635225]], [[1.4666551]]...</td>\n",
       "      <td>[[[[0.13451356]], [[0.5188112]], [[0.]], [[0.8...</td>\n",
       "      <td>[[[[0.53687906]], [[0.9690064]], [[0.34072238]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>[[[[1.1415956]], [[0.83224195]], [[1.3255785]]...</td>\n",
       "      <td>[[[[0.8741734]], [[0.51268244]], [[0.]], [[0.6...</td>\n",
       "      <td>[[[[1.0738424]], [[1.2320905]], [[0.22668292]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>[[[[1.1332208]], [[1.0605737]], [[1.2215495]],...</td>\n",
       "      <td>[[[[0.9031067]], [[0.7390998]], [[0.06612092]]...</td>\n",
       "      <td>[[[[1.0901456]], [[1.7403288]], [[0.2320695]],...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>[[[[1.0110648]], [[0.49118945]], [[0.6722478]]...</td>\n",
       "      <td>[[[[0.26090646]], [[0.4915446]], [[0.]], [[0.5...</td>\n",
       "      <td>[[[[0.68978417]], [[1.0480206]], [[0.12954687]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>[[[[1.0336659]], [[1.4389191]], [[1.7736214]],...</td>\n",
       "      <td>[[[[0.6828091]], [[1.2736242]], [[0.]], [[0.81...</td>\n",
       "      <td>[[[[1.0234927]], [[1.3498822]], [[0.1341014]],...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>[[[[0.9500895]], [[1.1227694]], [[1.0647306]],...</td>\n",
       "      <td>[[[[0.62980247]], [[0.9979253]], [[0.]], [[0.8...</td>\n",
       "      <td>[[[[1.461324]], [[0.99038476]], [[0.2844578]],...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>[[[[0.77845645]], [[1.3678604]], [[0.86269087]...</td>\n",
       "      <td>[[[[0.5852506]], [[1.1949348]], [[0.]], [[0.73...</td>\n",
       "      <td>[[[[0.5433132]], [[1.2485464]], [[0.17418973]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>[[[[0.97205406]], [[1.4208357]], [[1.216743]],...</td>\n",
       "      <td>[[[[0.66701365]], [[1.2526823]], [[0.]], [[0.7...</td>\n",
       "      <td>[[[[1.0030321]], [[1.3031648]], [[0.19537698]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>[[[[0.74174446]], [[0.7223051]], [[1.0954959]]...</td>\n",
       "      <td>[[[[0.35274163]], [[0.55216503]], [[0.17879833...</td>\n",
       "      <td>[[[[0.83245265]], [[1.152724]], [[0.15012541]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>[[[[1.1669189]], [[1.0897658]], [[1.0314052]],...</td>\n",
       "      <td>[[[[0.5617358]], [[1.1176395]], [[0.]], [[0.51...</td>\n",
       "      <td>[[[[0.70664]], [[1.1996003]], [[0.1958227]], [...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>[[[[0.845223]], [[0.7685576]], [[0.7256854]], ...</td>\n",
       "      <td>[[[[0.7849738]], [[0.62364304]], [[0.]], [[0.9...</td>\n",
       "      <td>[[[[1.2924833]], [[0.903612]], [[0.24620248]],...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>[[[[0.7611295]], [[0.65852946]], [[0.7858288]]...</td>\n",
       "      <td>[[[[0.05862333]], [[0.62993896]], [[0.]], [[0....</td>\n",
       "      <td>[[[[0.26548663]], [[1.0621603]], [[0.18325467]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>[[[[0.75935]], [[1.2760599]], [[0.93592846]], ...</td>\n",
       "      <td>[[[[0.18779281]], [[1.2588983]], [[0.]], [[0.8...</td>\n",
       "      <td>[[[[0.48144996]], [[1.3685968]], [[0.28038883]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>[[[[0.8676403]], [[0.76046073]], [[0.7795102]]...</td>\n",
       "      <td>[[[[0.18108624]], [[0.57195485]], [[0.02363325...</td>\n",
       "      <td>[[[[0.7851796]], [[1.2392812]], [[0.11143316]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>[[[[1.0240232]], [[0.7716706]], [[1.0018004]],...</td>\n",
       "      <td>[[[[0.8958773]], [[0.5539943]], [[0.]], [[0.88...</td>\n",
       "      <td>[[[[1.5096719]], [[1.1969093]], [[0.21241768]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>[[[[1.3516818]], [[0.59457886]], [[0.6501473]]...</td>\n",
       "      <td>[[[[1.2445948]], [[0.61792845]], [[0.]], [[1.5...</td>\n",
       "      <td>[[[[1.9658458]], [[1.3719904]], [[0.2847221]],...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>[[[[1.0803607]], [[0.8572496]], [[0.661375]], ...</td>\n",
       "      <td>[[[[0.23679414]], [[0.63063484]], [[0.]], [[0....</td>\n",
       "      <td>[[[[0.5026356]], [[1.3765979]], [[0.18369342]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>[[[[0.6511526]], [[1.2767099]], [[1.8592609]],...</td>\n",
       "      <td>[[[[0.29985696]], [[1.4203157]], [[0.0728467]]...</td>\n",
       "      <td>[[[[0.58866364]], [[2.1226525]], [[0.19540752]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>[[[[0.8324348]], [[1.4644921]], [[0.32241204]]...</td>\n",
       "      <td>[[[[0.4247341]], [[1.231321]], [[0.]], [[1.217...</td>\n",
       "      <td>[[[[0.49447104]], [[1.3842416]], [[0.24582903]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>[[[[0.93357134]], [[0.94392186]], [[1.0063349]...</td>\n",
       "      <td>[[[[0.6972691]], [[0.746612]], [[0.]], [[0.654...</td>\n",
       "      <td>[[[[0.956296]], [[1.2538555]], [[0.19633849]],...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>[[[[0.49736002]], [[0.6795289]], [[0.8712264]]...</td>\n",
       "      <td>[[[[0.1388904]], [[0.6626899]], [[0.]], [[0.93...</td>\n",
       "      <td>[[[[0.6696428]], [[1.066048]], [[0.24048187]],...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>[[[[0.81544185]], [[0.95267093]], [[1.7959827]...</td>\n",
       "      <td>[[[[0.44727868]], [[0.9140834]], [[0.]], [[0.7...</td>\n",
       "      <td>[[[[0.95479614]], [[1.0661185]], [[0.28821576]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>[[[[1.0955446]], [[0.79170877]], [[1.7100291]]...</td>\n",
       "      <td>[[[[0.75882703]], [[0.6083473]], [[0.]], [[0.8...</td>\n",
       "      <td>[[[[0.91333044]], [[1.0262234]], [[0.29919642]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>[[[[0.3610353]], [[1.0904068]], [[0.5535994]],...</td>\n",
       "      <td>[[[[0.09143831]], [[0.6420338]], [[0.]], [[0.6...</td>\n",
       "      <td>[[[[0.6517457]], [[1.3617579]], [[0.31195116]]...</td>\n",
       "      <td>[tensor(0., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>[[[[1.5823609]], [[0.9570341]], [[0.982788]], ...</td>\n",
       "      <td>[[[[1.105972]], [[0.84553766]], [[0.]], [[0.98...</td>\n",
       "      <td>[[[[1.1124439]], [[1.2486645]], [[0.14579572]]...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>[[[[0.541059]], [[0.92346364]], [[1.0396473]],...</td>\n",
       "      <td>[[[[0.0728194]], [[0.6804984]], [[0.03106287]]...</td>\n",
       "      <td>[[[[0.6886585]], [[1.2931173]], [[0.1723956]],...</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  \\\n",
       "0    [[[[0.7136695]], [[0.5966748]], [[1.5684245]],...   \n",
       "1    [[[[0.87442553]], [[1.2025621]], [[0.8099077]]...   \n",
       "2    [[[[0.91123986]], [[1.1268694]], [[1.5741594]]...   \n",
       "3    [[[[1.1057353]], [[1.0990793]], [[1.2561587]],...   \n",
       "4    [[[[0.3907119]], [[1.0809014]], [[1.4426181]],...   \n",
       "5    [[[[0.99570894]], [[0.83248633]], [[1.4694465]...   \n",
       "6    [[[[0.76090866]], [[0.66342896]], [[0.88885367...   \n",
       "7    [[[[0.7673841]], [[1.0669808]], [[0.84954536]]...   \n",
       "8    [[[[0.37856206]], [[0.6023888]], [[0.8931349]]...   \n",
       "9    [[[[0.66082174]], [[0.90579623]], [[0.3597993]...   \n",
       "10   [[[[0.9646332]], [[1.3950489]], [[0.5280791]],...   \n",
       "11   [[[[0.63429505]], [[1.4681506]], [[0.6332361]]...   \n",
       "12   [[[[1.0837971]], [[0.7644463]], [[1.2890801]],...   \n",
       "13   [[[[0.8955999]], [[0.95184493]], [[1.6119937]]...   \n",
       "14   [[[[1.0990928]], [[0.70393604]], [[0.41227022]...   \n",
       "15   [[[[0.6503165]], [[0.79853415]], [[0.73378366]...   \n",
       "16   [[[[0.97953176]], [[0.8293885]], [[0.8897084]]...   \n",
       "17   [[[[0.9519514]], [[1.5046413]], [[1.5821965]],...   \n",
       "18   [[[[0.7706637]], [[0.7124087]], [[0.5919047]],...   \n",
       "19   [[[[1.0570626]], [[0.92358977]], [[0.8314927]]...   \n",
       "20   [[[[0.46718642]], [[0.8464217]], [[0.6812674]]...   \n",
       "21   [[[[1.1784594]], [[1.0386066]], [[0.51394343]]...   \n",
       "22   [[[[0.8702978]], [[0.43718627]], [[0.4393292]]...   \n",
       "23   [[[[0.54999167]], [[0.98559886]], [[0.72847044...   \n",
       "24   [[[[0.72751796]], [[0.74342585]], [[1.6269205]...   \n",
       "25   [[[[1.0140551]], [[0.9254571]], [[1.0211936]],...   \n",
       "26   [[[[0.99596035]], [[0.6640087]], [[0.5937315]]...   \n",
       "27   [[[[0.55328953]], [[1.4391109]], [[0.9278571]]...   \n",
       "28   [[[[1.6971041]], [[0.97803676]], [[1.2333802]]...   \n",
       "29   [[[[0.68470556]], [[1.1094121]], [[1.0987729]]...   \n",
       "..                                                 ...   \n",
       "444  [[[[1.0358715]], [[1.2295281]], [[0.9794683]],...   \n",
       "445  [[[[1.0349112]], [[0.75016]], [[1.5438305]], [...   \n",
       "446  [[[[1.2600394]], [[0.72507954]], [[0.8160462]]...   \n",
       "447  [[[[0.5239251]], [[1.4076585]], [[0.6563418]],...   \n",
       "448  [[[[0.96932584]], [[0.8635225]], [[1.4666551]]...   \n",
       "449  [[[[1.1415956]], [[0.83224195]], [[1.3255785]]...   \n",
       "450  [[[[1.1332208]], [[1.0605737]], [[1.2215495]],...   \n",
       "451  [[[[1.0110648]], [[0.49118945]], [[0.6722478]]...   \n",
       "452  [[[[1.0336659]], [[1.4389191]], [[1.7736214]],...   \n",
       "453  [[[[0.9500895]], [[1.1227694]], [[1.0647306]],...   \n",
       "454  [[[[0.77845645]], [[1.3678604]], [[0.86269087]...   \n",
       "455  [[[[0.97205406]], [[1.4208357]], [[1.216743]],...   \n",
       "456  [[[[0.74174446]], [[0.7223051]], [[1.0954959]]...   \n",
       "457  [[[[1.1669189]], [[1.0897658]], [[1.0314052]],...   \n",
       "458  [[[[0.845223]], [[0.7685576]], [[0.7256854]], ...   \n",
       "459  [[[[0.7611295]], [[0.65852946]], [[0.7858288]]...   \n",
       "460  [[[[0.75935]], [[1.2760599]], [[0.93592846]], ...   \n",
       "461  [[[[0.8676403]], [[0.76046073]], [[0.7795102]]...   \n",
       "462  [[[[1.0240232]], [[0.7716706]], [[1.0018004]],...   \n",
       "463  [[[[1.3516818]], [[0.59457886]], [[0.6501473]]...   \n",
       "464  [[[[1.0803607]], [[0.8572496]], [[0.661375]], ...   \n",
       "465  [[[[0.6511526]], [[1.2767099]], [[1.8592609]],...   \n",
       "466  [[[[0.8324348]], [[1.4644921]], [[0.32241204]]...   \n",
       "467  [[[[0.93357134]], [[0.94392186]], [[1.0063349]...   \n",
       "468  [[[[0.49736002]], [[0.6795289]], [[0.8712264]]...   \n",
       "469  [[[[0.81544185]], [[0.95267093]], [[1.7959827]...   \n",
       "470  [[[[1.0955446]], [[0.79170877]], [[1.7100291]]...   \n",
       "471  [[[[0.3610353]], [[1.0904068]], [[0.5535994]],...   \n",
       "472  [[[[1.5823609]], [[0.9570341]], [[0.982788]], ...   \n",
       "473  [[[[0.541059]], [[0.92346364]], [[1.0396473]],...   \n",
       "\n",
       "                                                     1  \\\n",
       "0    [[[[0.2606857]], [[0.76252264]], [[0.]], [[0.8...   \n",
       "1    [[[[0.6031779]], [[0.954708]], [[0.00806442]],...   \n",
       "2    [[[[0.50245315]], [[0.8697139]], [[0.]], [[0.6...   \n",
       "3    [[[[0.31014588]], [[0.8029127]], [[0.]], [[0.7...   \n",
       "4    [[[[0.0794258]], [[0.92135847]], [[0.2039707]]...   \n",
       "5    [[[[0.24164061]], [[0.7189417]], [[0.]], [[0.9...   \n",
       "6    [[[[0.13365938]], [[0.6038446]], [[0.]], [[1.0...   \n",
       "7    [[[[0.1397689]], [[1.0670974]], [[0.]], [[0.78...   \n",
       "8    [[[[0.12124376]], [[0.66590416]], [[0.]], [[0....   \n",
       "9    [[[[0.14087407]], [[0.82040477]], [[0.00061371...   \n",
       "10   [[[[0.6118944]], [[1.2479125]], [[0.01305945]]...   \n",
       "11   [[[[0.33809397]], [[1.0178871]], [[0.]], [[1.1...   \n",
       "12   [[[[0.10495465]], [[0.5524683]], [[0.]], [[0.7...   \n",
       "13   [[[[0.7687045]], [[0.63126314]], [[0.02766945]...   \n",
       "14   [[[[0.65635604]], [[0.62953955]], [[0.]], [[0....   \n",
       "15   [[[[0.2313944]], [[0.70172095]], [[0.]], [[0.7...   \n",
       "16   [[[[0.48563817]], [[0.6013953]], [[0.00240682]...   \n",
       "17   [[[[0.56910115]], [[1.4101962]], [[0.]], [[0.7...   \n",
       "18   [[[[0.5983701]], [[0.66026676]], [[0.00182363]...   \n",
       "19   [[[[0.87686324]], [[0.76871157]], [[0.]], [[1....   \n",
       "20   [[[[0.16215721]], [[0.7701032]], [[0.]], [[1.1...   \n",
       "21   [[[[0.8511178]], [[0.8200752]], [[0.00610646]]...   \n",
       "22   [[[[0.7992814]], [[0.62536347]], [[0.02263787]...   \n",
       "23   [[[[0.32748532]], [[0.7007353]], [[0.]], [[0.7...   \n",
       "24   [[[[0.37619206]], [[0.6912724]], [[0.]], [[0.8...   \n",
       "25   [[[[0.89209735]], [[0.8156954]], [[0.12809315]...   \n",
       "26   [[[[0.48245692]], [[0.5905515]], [[0.]], [[1.0...   \n",
       "27   [[[[0.15273508]], [[0.9719503]], [[0.01391844]...   \n",
       "28   [[[[1.4583683]], [[0.88298976]], [[0.01492494]...   \n",
       "29   [[[[0.19278543]], [[1.1968535]], [[0.]], [[0.8...   \n",
       "..                                                 ...   \n",
       "444  [[[[0.70956874]], [[0.977788]], [[0.00397338]]...   \n",
       "445  [[[[0.64699465]], [[0.6856429]], [[0.14126514]...   \n",
       "446  [[[[0.73059005]], [[0.6331663]], [[0.]], [[0.7...   \n",
       "447  [[[[0.1708772]], [[0.7494808]], [[0.]], [[0.70...   \n",
       "448  [[[[0.13451356]], [[0.5188112]], [[0.]], [[0.8...   \n",
       "449  [[[[0.8741734]], [[0.51268244]], [[0.]], [[0.6...   \n",
       "450  [[[[0.9031067]], [[0.7390998]], [[0.06612092]]...   \n",
       "451  [[[[0.26090646]], [[0.4915446]], [[0.]], [[0.5...   \n",
       "452  [[[[0.6828091]], [[1.2736242]], [[0.]], [[0.81...   \n",
       "453  [[[[0.62980247]], [[0.9979253]], [[0.]], [[0.8...   \n",
       "454  [[[[0.5852506]], [[1.1949348]], [[0.]], [[0.73...   \n",
       "455  [[[[0.66701365]], [[1.2526823]], [[0.]], [[0.7...   \n",
       "456  [[[[0.35274163]], [[0.55216503]], [[0.17879833...   \n",
       "457  [[[[0.5617358]], [[1.1176395]], [[0.]], [[0.51...   \n",
       "458  [[[[0.7849738]], [[0.62364304]], [[0.]], [[0.9...   \n",
       "459  [[[[0.05862333]], [[0.62993896]], [[0.]], [[0....   \n",
       "460  [[[[0.18779281]], [[1.2588983]], [[0.]], [[0.8...   \n",
       "461  [[[[0.18108624]], [[0.57195485]], [[0.02363325...   \n",
       "462  [[[[0.8958773]], [[0.5539943]], [[0.]], [[0.88...   \n",
       "463  [[[[1.2445948]], [[0.61792845]], [[0.]], [[1.5...   \n",
       "464  [[[[0.23679414]], [[0.63063484]], [[0.]], [[0....   \n",
       "465  [[[[0.29985696]], [[1.4203157]], [[0.0728467]]...   \n",
       "466  [[[[0.4247341]], [[1.231321]], [[0.]], [[1.217...   \n",
       "467  [[[[0.6972691]], [[0.746612]], [[0.]], [[0.654...   \n",
       "468  [[[[0.1388904]], [[0.6626899]], [[0.]], [[0.93...   \n",
       "469  [[[[0.44727868]], [[0.9140834]], [[0.]], [[0.7...   \n",
       "470  [[[[0.75882703]], [[0.6083473]], [[0.]], [[0.8...   \n",
       "471  [[[[0.09143831]], [[0.6420338]], [[0.]], [[0.6...   \n",
       "472  [[[[1.105972]], [[0.84553766]], [[0.]], [[0.98...   \n",
       "473  [[[[0.0728194]], [[0.6804984]], [[0.03106287]]...   \n",
       "\n",
       "                                                     2  \\\n",
       "0    [[[[0.8388147]], [[1.1766884]], [[0.1948912]],...   \n",
       "1    [[[[0.79707575]], [[1.1046199]], [[0.08605583]...   \n",
       "2    [[[[0.6785448]], [[1.2957569]], [[0.0453416]],...   \n",
       "3    [[[[0.99477756]], [[1.0686543]], [[0.38822544]...   \n",
       "4    [[[[0.7034851]], [[1.2801485]], [[0.2507491]],...   \n",
       "5    [[[[0.5510677]], [[1.0326794]], [[0.24347706]]...   \n",
       "6    [[[[0.7100026]], [[1.1725931]], [[0.17521872]]...   \n",
       "7    [[[[0.8027326]], [[1.1633745]], [[0.3125465]],...   \n",
       "8    [[[[0.71915686]], [[1.2433087]], [[0.26504898]...   \n",
       "9    [[[[1.0845159]], [[1.140809]], [[0.36609995]],...   \n",
       "10   [[[[0.69267535]], [[1.6574126]], [[0.20235921]...   \n",
       "11   [[[[1.0219374]], [[1.7998372]], [[0.24411662]]...   \n",
       "12   [[[[0.65444]], [[0.8391235]], [[0.2665369]], [...   \n",
       "13   [[[[1.2394602]], [[1.0608716]], [[0.19582509]]...   \n",
       "14   [[[[0.86763823]], [[0.99151564]], [[0.2591284]...   \n",
       "15   [[[[0.7999359]], [[1.3417534]], [[0.09992491]]...   \n",
       "16   [[[[0.94594485]], [[1.380919]], [[0.28708953]]...   \n",
       "17   [[[[0.5510655]], [[1.7857206]], [[0.34002197]]...   \n",
       "18   [[[[1.1548083]], [[1.1908001]], [[0.21185969]]...   \n",
       "19   [[[[1.4832199]], [[1.252472]], [[0.2505346]], ...   \n",
       "20   [[[[1.0154465]], [[1.412256]], [[0.41162312]],...   \n",
       "21   [[[[0.9787493]], [[1.1150758]], [[0.02609569]]...   \n",
       "22   [[[[1.3232431]], [[1.4357141]], [[0.21391706]]...   \n",
       "23   [[[[0.5517086]], [[1.2463572]], [[0.20973606]]...   \n",
       "24   [[[[0.685026]], [[1.181264]], [[0.18105818]], ...   \n",
       "25   [[[[1.2551823]], [[1.6936402]], [[0.14405799]]...   \n",
       "26   [[[[0.93079925]], [[1.2005582]], [[0.3911389]]...   \n",
       "27   [[[[0.65038145]], [[1.5017123]], [[0.11106776]...   \n",
       "28   [[[[1.4840847]], [[1.3498926]], [[0.15299903]]...   \n",
       "29   [[[[0.62063473]], [[1.3134845]], [[0.19068573]...   \n",
       "..                                                 ...   \n",
       "444  [[[[0.8566985]], [[1.7565303]], [[0.28917497]]...   \n",
       "445  [[[[0.9579328]], [[1.0833677]], [[0.1921882]],...   \n",
       "446  [[[[0.6390508]], [[1.4283442]], [[0.17257033]]...   \n",
       "447  [[[[0.98789376]], [[1.1657844]], [[0.3285892]]...   \n",
       "448  [[[[0.53687906]], [[0.9690064]], [[0.34072238]...   \n",
       "449  [[[[1.0738424]], [[1.2320905]], [[0.22668292]]...   \n",
       "450  [[[[1.0901456]], [[1.7403288]], [[0.2320695]],...   \n",
       "451  [[[[0.68978417]], [[1.0480206]], [[0.12954687]...   \n",
       "452  [[[[1.0234927]], [[1.3498822]], [[0.1341014]],...   \n",
       "453  [[[[1.461324]], [[0.99038476]], [[0.2844578]],...   \n",
       "454  [[[[0.5433132]], [[1.2485464]], [[0.17418973]]...   \n",
       "455  [[[[1.0030321]], [[1.3031648]], [[0.19537698]]...   \n",
       "456  [[[[0.83245265]], [[1.152724]], [[0.15012541]]...   \n",
       "457  [[[[0.70664]], [[1.1996003]], [[0.1958227]], [...   \n",
       "458  [[[[1.2924833]], [[0.903612]], [[0.24620248]],...   \n",
       "459  [[[[0.26548663]], [[1.0621603]], [[0.18325467]...   \n",
       "460  [[[[0.48144996]], [[1.3685968]], [[0.28038883]...   \n",
       "461  [[[[0.7851796]], [[1.2392812]], [[0.11143316]]...   \n",
       "462  [[[[1.5096719]], [[1.1969093]], [[0.21241768]]...   \n",
       "463  [[[[1.9658458]], [[1.3719904]], [[0.2847221]],...   \n",
       "464  [[[[0.5026356]], [[1.3765979]], [[0.18369342]]...   \n",
       "465  [[[[0.58866364]], [[2.1226525]], [[0.19540752]...   \n",
       "466  [[[[0.49447104]], [[1.3842416]], [[0.24582903]...   \n",
       "467  [[[[0.956296]], [[1.2538555]], [[0.19633849]],...   \n",
       "468  [[[[0.6696428]], [[1.066048]], [[0.24048187]],...   \n",
       "469  [[[[0.95479614]], [[1.0661185]], [[0.28821576]...   \n",
       "470  [[[[0.91333044]], [[1.0262234]], [[0.29919642]...   \n",
       "471  [[[[0.6517457]], [[1.3617579]], [[0.31195116]]...   \n",
       "472  [[[[1.1124439]], [[1.2486645]], [[0.14579572]]...   \n",
       "473  [[[[0.6886585]], [[1.2931173]], [[0.1723956]],...   \n",
       "\n",
       "                                     3  \n",
       "0    [tensor(1., dtype=torch.float64)]  \n",
       "1    [tensor(1., dtype=torch.float64)]  \n",
       "2    [tensor(1., dtype=torch.float64)]  \n",
       "3    [tensor(1., dtype=torch.float64)]  \n",
       "4    [tensor(1., dtype=torch.float64)]  \n",
       "5    [tensor(1., dtype=torch.float64)]  \n",
       "6    [tensor(1., dtype=torch.float64)]  \n",
       "7    [tensor(1., dtype=torch.float64)]  \n",
       "8    [tensor(1., dtype=torch.float64)]  \n",
       "9    [tensor(0., dtype=torch.float64)]  \n",
       "10   [tensor(0., dtype=torch.float64)]  \n",
       "11   [tensor(0., dtype=torch.float64)]  \n",
       "12   [tensor(1., dtype=torch.float64)]  \n",
       "13   [tensor(1., dtype=torch.float64)]  \n",
       "14   [tensor(0., dtype=torch.float64)]  \n",
       "15   [tensor(0., dtype=torch.float64)]  \n",
       "16   [tensor(0., dtype=torch.float64)]  \n",
       "17   [tensor(0., dtype=torch.float64)]  \n",
       "18   [tensor(1., dtype=torch.float64)]  \n",
       "19   [tensor(1., dtype=torch.float64)]  \n",
       "20   [tensor(0., dtype=torch.float64)]  \n",
       "21   [tensor(1., dtype=torch.float64)]  \n",
       "22   [tensor(1., dtype=torch.float64)]  \n",
       "23   [tensor(1., dtype=torch.float64)]  \n",
       "24   [tensor(1., dtype=torch.float64)]  \n",
       "25   [tensor(1., dtype=torch.float64)]  \n",
       "26   [tensor(1., dtype=torch.float64)]  \n",
       "27   [tensor(1., dtype=torch.float64)]  \n",
       "28   [tensor(0., dtype=torch.float64)]  \n",
       "29   [tensor(0., dtype=torch.float64)]  \n",
       "..                                 ...  \n",
       "444  [tensor(0., dtype=torch.float64)]  \n",
       "445  [tensor(0., dtype=torch.float64)]  \n",
       "446  [tensor(0., dtype=torch.float64)]  \n",
       "447  [tensor(0., dtype=torch.float64)]  \n",
       "448  [tensor(0., dtype=torch.float64)]  \n",
       "449  [tensor(1., dtype=torch.float64)]  \n",
       "450  [tensor(1., dtype=torch.float64)]  \n",
       "451  [tensor(0., dtype=torch.float64)]  \n",
       "452  [tensor(0., dtype=torch.float64)]  \n",
       "453  [tensor(0., dtype=torch.float64)]  \n",
       "454  [tensor(0., dtype=torch.float64)]  \n",
       "455  [tensor(0., dtype=torch.float64)]  \n",
       "456  [tensor(1., dtype=torch.float64)]  \n",
       "457  [tensor(1., dtype=torch.float64)]  \n",
       "458  [tensor(1., dtype=torch.float64)]  \n",
       "459  [tensor(1., dtype=torch.float64)]  \n",
       "460  [tensor(0., dtype=torch.float64)]  \n",
       "461  [tensor(1., dtype=torch.float64)]  \n",
       "462  [tensor(0., dtype=torch.float64)]  \n",
       "463  [tensor(0., dtype=torch.float64)]  \n",
       "464  [tensor(1., dtype=torch.float64)]  \n",
       "465  [tensor(1., dtype=torch.float64)]  \n",
       "466  [tensor(1., dtype=torch.float64)]  \n",
       "467  [tensor(1., dtype=torch.float64)]  \n",
       "468  [tensor(1., dtype=torch.float64)]  \n",
       "469  [tensor(0., dtype=torch.float64)]  \n",
       "470  [tensor(0., dtype=torch.float64)]  \n",
       "471  [tensor(0., dtype=torch.float64)]  \n",
       "472  [tensor(1., dtype=torch.float64)]  \n",
       "473  [tensor(1., dtype=torch.float64)]  \n",
       "\n",
       "[474 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_pickle('all features/incep-vggface/inception_resnet_vggface_features_train.pl')\n",
    "test_set = pd.read_pickle('all features/incep-vggface/inception_resnet_vggface_features_test.pl')\n",
    "val_set = pd.read_pickle('all features/incep-vggface/inception_resnet_vggface_features_val.pl')\n",
    "val_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.2266511, 1.0417311, 1.1330203, 0.86150473, ...</td>\n",
       "      <td>[0.97100186, 0.5840728, 0.018708272, 0.6757692...</td>\n",
       "      <td>[1.453161, 0.9682333, 0.0762357, 2.2394767, 1....</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.9260725, 0.5731336, 0.8489482, 0.6313456, 1...</td>\n",
       "      <td>[0.3021238, 0.57566774, 0.013932347, 0.6377456...</td>\n",
       "      <td>[0.7886908, 1.0985806, 0.19914995, 2.2344904, ...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.8079407, 0.84246206, 0.89299726, 0.6448495,...</td>\n",
       "      <td>[0.6755501, 0.6909119, 0.0015019281, 0.8135175...</td>\n",
       "      <td>[1.0263835, 1.6801147, 0.12214534, 3.239491, 2...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.599945, 1.222887, 1.296843, 1.0004117, 0.99...</td>\n",
       "      <td>[0.3050562, 1.0690634, 0.010042003, 0.8362427,...</td>\n",
       "      <td>[0.45392486, 1.3208184, 0.04594949, 2.8563154,...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.74703896, 1.3423767, 1.4105116, 0.7901356, ...</td>\n",
       "      <td>[0.076150075, 1.34196, 0.0, 1.0045176, 1.48474...</td>\n",
       "      <td>[0.33487615, 1.3349226, 0.07892446, 2.7373383,...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.88963294, 0.5910753, 1.0034066, 1.2651983, ...</td>\n",
       "      <td>[0.5554142, 0.5313716, 0.0, 1.3494354, 1.17695...</td>\n",
       "      <td>[0.7941327, 0.9516872, 0.16922458, 2.723517, 1...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.38441232, 0.567524, 0.6700937, 0.86411256, ...</td>\n",
       "      <td>[0.15692724, 0.77687633, 0.0, 0.8505674, 1.627...</td>\n",
       "      <td>[0.8577994, 1.0316093, 0.25254643, 2.531352, 1...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.43136236, 0.8914018, 1.1213691, 0.7663166, ...</td>\n",
       "      <td>[0.1252123, 0.75570023, 0.0, 0.7990814, 1.6406...</td>\n",
       "      <td>[0.6947966, 1.0000659, 0.17763479, 2.4569223, ...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1.0548836, 0.57110304, 0.57705915, 0.9964003,...</td>\n",
       "      <td>[0.25558898, 0.5446507, 0.0, 0.92947555, 1.051...</td>\n",
       "      <td>[0.78453887, 1.2621708, 0.22997604, 2.8855104,...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.62746835, 0.46289912, 0.8168433, 0.6603487,...</td>\n",
       "      <td>[0.07032215, 0.5805372, 0.0, 0.7073519, 1.2059...</td>\n",
       "      <td>[0.57190776, 1.3017917, 0.2964571, 2.4923735, ...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1.1941446, 0.9863214, 1.0455906, 0.8168348, 1...</td>\n",
       "      <td>[0.51242816, 0.81379545, 0.0, 0.81825596, 1.34...</td>\n",
       "      <td>[0.6554679, 1.2440021, 0.28184587, 2.394824, 1...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1.4160447, 1.3218861, 0.9660971, 1.33309, 0.7...</td>\n",
       "      <td>[0.98665804, 0.91159964, 0.0, 1.0325896, 1.412...</td>\n",
       "      <td>[1.1204507, 1.3650155, 0.20188247, 2.6159732, ...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1.1593821, 0.7785032, 1.1378238, 0.72918344, ...</td>\n",
       "      <td>[0.78312653, 0.52499694, 0.01604845, 0.9166615...</td>\n",
       "      <td>[1.0351921, 1.1763014, 0.06259541, 2.475656, 0...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.8249949, 1.2512265, 0.4579049, 1.2566013, 1...</td>\n",
       "      <td>[0.2741711, 1.1039472, 0.0, 1.6175538, 2.04132...</td>\n",
       "      <td>[0.8148253, 1.77486, 0.23513056, 3.1608572, 1....</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.35373518, 0.716912, 0.9005486, 1.1021699, 1...</td>\n",
       "      <td>[0.13621587, 0.51738465, 0.01489074, 0.8032220...</td>\n",
       "      <td>[0.7797959, 1.322388, 0.123931125, 2.4144814, ...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1.1505605, 0.5084761, 1.3164309, 0.54808956, ...</td>\n",
       "      <td>[0.5483058, 0.5331195, 0.0, 0.82636046, 1.2954...</td>\n",
       "      <td>[0.63905555, 1.0674386, 0.2660905, 2.745481, 0...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.47456804, 0.35149944, 0.7526036, 0.51093584...</td>\n",
       "      <td>[0.41485345, 0.6650646, 0.0, 0.84842837, 2.083...</td>\n",
       "      <td>[0.7696068, 1.2912567, 0.21132345, 3.0863757, ...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.9090706, 0.8371268, 0.9428199, 0.53306776, ...</td>\n",
       "      <td>[0.62624407, 0.53010684, 0.027189752, 0.553745...</td>\n",
       "      <td>[1.0877213, 1.223011, 0.3041957, 2.027799, 2.1...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1.0827852, 1.4389306, 1.431331, 0.77310884, 0...</td>\n",
       "      <td>[0.5586376, 1.0527498, 0.0, 0.81319094, 1.4233...</td>\n",
       "      <td>[0.7367632, 1.2793095, 0.20742427, 2.5475137, ...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.69452995, 1.1959325, 1.3090881, 1.2940817, ...</td>\n",
       "      <td>[0.087833904, 1.0270096, 0.15224127, 1.3106239...</td>\n",
       "      <td>[0.49185985, 1.317891, 0.2634306, 3.4356647, 0...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.97954327, 0.9856241, 0.67270476, 0.9674342,...</td>\n",
       "      <td>[0.20067716, 0.75440305, 0.0, 0.7237635, 1.248...</td>\n",
       "      <td>[0.9686982, 1.0572011, 0.30760467, 1.9652164, ...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.8700231, 1.0057819, 0.8614572, 0.99150026, ...</td>\n",
       "      <td>[0.098198116, 0.76423275, 0.0, 0.8204883, 1.52...</td>\n",
       "      <td>[0.72697943, 1.469209, 0.21518166, 2.7718883, ...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.92678, 0.7764833, 0.9714116, 0.95193124, 1....</td>\n",
       "      <td>[0.7516254, 0.5992485, 0.018889975, 0.51026446...</td>\n",
       "      <td>[1.1163119, 1.0591897, 0.10162194, 2.3445523, ...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[1.0752004, 1.3420398, 1.3904576, 0.7037693, 0...</td>\n",
       "      <td>[0.5616659, 1.0250338, 0.0, 0.555512, 1.754320...</td>\n",
       "      <td>[0.34901568, 1.3939581, 0.09273015, 1.5329504,...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.5627111, 0.33239597, 0.9758223, 0.86889356,...</td>\n",
       "      <td>[0.36074507, 0.5543164, 0.0246257, 0.6868933, ...</td>\n",
       "      <td>[0.98933667, 1.3660069, 0.23138268, 2.5460649,...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.42432985, 0.88932836, 0.7727695, 0.698427, ...</td>\n",
       "      <td>[0.19513634, 0.7816249, 0.007126488, 0.8655882...</td>\n",
       "      <td>[0.5798936, 1.8104128, 0.110991284, 3.5444713,...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.81034905, 1.1269977, 1.3041121, 0.70037943,...</td>\n",
       "      <td>[0.5275315, 0.7550219, 0.13558236, 0.64960515,...</td>\n",
       "      <td>[0.70193136, 1.066397, 0.1152596, 2.469129, 2....</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[1.4452187, 0.9991081, 1.871594, 0.50349927, 0...</td>\n",
       "      <td>[1.1188992, 0.79463077, 0.4278977, 0.73458606,...</td>\n",
       "      <td>[1.4008639, 0.90516233, 0.11431219, 1.9774063,...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.9091235, 1.0322626, 1.0045466, 0.9273859, 0...</td>\n",
       "      <td>[0.16400178, 0.81292033, 0.0, 0.77544665, 1.28...</td>\n",
       "      <td>[0.6965086, 0.9007636, 0.24614973, 2.0569568, ...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.78108156, 1.1517342, 1.6094176, 0.89147735,...</td>\n",
       "      <td>[0.47887766, 0.6499354, 0.040433116, 0.9524293...</td>\n",
       "      <td>[0.9605986, 1.0693516, 0.23679422, 2.546359, 1...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9164</th>\n",
       "      <td>[1.1048782, 0.73922986, 1.5323056, 0.51722085,...</td>\n",
       "      <td>[0.6438666, 0.5630163, 0.32229805, 0.64934194,...</td>\n",
       "      <td>[0.8257044, 1.5426817, 0.4612856, 2.633638, 1....</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9165</th>\n",
       "      <td>[0.80980843, 0.70740914, 1.1179122, 0.7712648,...</td>\n",
       "      <td>[0.18381646, 0.5840082, 0.0, 0.7078125, 1.3878...</td>\n",
       "      <td>[0.8567538, 1.3019444, 0.30616665, 2.6546888, ...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9166</th>\n",
       "      <td>[0.96898997, 1.1219271, 1.4396054, 0.75455433,...</td>\n",
       "      <td>[0.6854943, 0.9676646, 0.02073163, 1.036068, 0...</td>\n",
       "      <td>[0.81464475, 1.4109824, 0.13531299, 3.1359715,...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9167</th>\n",
       "      <td>[1.3452278, 1.0870333, 0.95577836, 1.2325946, ...</td>\n",
       "      <td>[1.0116054, 0.9115115, 0.0012172187, 0.9337668...</td>\n",
       "      <td>[1.0095623, 1.4776814, 0.3107046, 2.8292027, 1...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9168</th>\n",
       "      <td>[0.91805845, 1.1170028, 1.4155775, 0.3886531, ...</td>\n",
       "      <td>[0.37767714, 0.8120428, 0.0, 0.8491515, 1.2917...</td>\n",
       "      <td>[0.5913154, 1.49932, 0.18408887, 2.3576136, 1....</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>[0.5329634, 0.6395203, 1.1510091, 0.8197139, 0...</td>\n",
       "      <td>[0.095873885, 0.5097374, 0.0, 0.7565736, 1.211...</td>\n",
       "      <td>[0.59695834, 1.1788837, 0.29237223, 2.1528356,...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9170</th>\n",
       "      <td>[1.0443552, 1.3376004, 0.5944006, 0.9581421, 1...</td>\n",
       "      <td>[0.24642737, 0.617437, 0.0, 0.9032993, 1.26322...</td>\n",
       "      <td>[0.71148777, 0.9920536, 0.21719979, 2.3901942,...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>[0.8338877, 1.3742892, 1.2247676, 0.9027906, 1...</td>\n",
       "      <td>[0.09795892, 1.0677215, 0.010224995, 0.6444095...</td>\n",
       "      <td>[0.2734422, 1.2083552, 0.11518024, 1.985456, 1...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9172</th>\n",
       "      <td>[1.3903974, 0.6801297, 1.1442487, 0.72706354, ...</td>\n",
       "      <td>[0.62551713, 0.5096431, 0.0, 0.8055614, 1.1171...</td>\n",
       "      <td>[0.5699313, 0.9061068, 0.25312608, 1.7731636, ...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9173</th>\n",
       "      <td>[0.83364034, 0.57737267, 1.5228044, 0.5410602,...</td>\n",
       "      <td>[0.14664185, 0.5826496, 0.35804835, 0.70127815...</td>\n",
       "      <td>[0.8640035, 1.0519197, 0.29561996, 2.3006248, ...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9174</th>\n",
       "      <td>[0.6703258, 0.36793125, 1.0731152, 1.1447587, ...</td>\n",
       "      <td>[0.36107522, 0.6076762, 0.0, 1.3822148, 1.7078...</td>\n",
       "      <td>[1.1852614, 1.2398369, 0.2702697, 3.190967, 1....</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9175</th>\n",
       "      <td>[0.42263326, 0.8727894, 1.1558088, 0.58081126,...</td>\n",
       "      <td>[0.069258034, 0.74368405, 0.0, 1.131066, 1.887...</td>\n",
       "      <td>[0.47906446, 1.2162832, 0.20168172, 2.8836854,...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9176</th>\n",
       "      <td>[0.48774904, 0.75401115, 1.1693717, 0.9749964,...</td>\n",
       "      <td>[0.11186211, 0.54658496, 0.0, 0.69178236, 1.10...</td>\n",
       "      <td>[0.65549016, 0.83333576, 0.35015267, 2.2339704...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9177</th>\n",
       "      <td>[0.66593206, 1.0699384, 1.2808576, 0.7722058, ...</td>\n",
       "      <td>[0.21776873, 0.8744145, 0.010778495, 0.4876124...</td>\n",
       "      <td>[0.3972997, 1.2266059, 0.07659598, 2.3354414, ...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9178</th>\n",
       "      <td>[0.98399085, 0.7547867, 1.4024857, 1.0391302, ...</td>\n",
       "      <td>[0.2671342, 0.7560413, 0.666515, 1.0998068, 1....</td>\n",
       "      <td>[0.8643138, 1.0525115, 0.5586691, 2.2994623, 1...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9179</th>\n",
       "      <td>[0.7389063, 1.0877801, 0.7402861, 1.0664952, 1...</td>\n",
       "      <td>[0.21765128, 0.57686234, 0.0, 0.7632327, 1.451...</td>\n",
       "      <td>[0.5098187, 1.0402429, 0.13221605, 2.6742883, ...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9180</th>\n",
       "      <td>[0.677361, 0.53459495, 0.6605791, 1.0548846, 1...</td>\n",
       "      <td>[0.033634603, 0.42966384, 0.0, 0.8245664, 2.02...</td>\n",
       "      <td>[0.817397, 0.9484475, 0.29730743, 1.9620632, 1...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9181</th>\n",
       "      <td>[1.3495919, 1.1840837, 1.316518, 1.3965293, 1....</td>\n",
       "      <td>[0.91882664, 0.6032505, 0.01750259, 0.66171956...</td>\n",
       "      <td>[1.0389292, 0.97529805, 0.10230906, 2.2153816,...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9182</th>\n",
       "      <td>[1.3185825, 1.4318628, 1.187987, 1.3841957, 1....</td>\n",
       "      <td>[0.90356916, 0.8591377, 0.016486736, 0.671565,...</td>\n",
       "      <td>[1.059758, 0.942966, 0.089776084, 2.2550201, 1...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9183</th>\n",
       "      <td>[0.8326618, 1.0701257, 1.1290746, 0.6957043, 0...</td>\n",
       "      <td>[0.109357424, 0.9189861, 0.0, 0.8184475, 1.413...</td>\n",
       "      <td>[0.88998353, 1.1392044, 0.29695988, 2.4473202,...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9184</th>\n",
       "      <td>[0.4731417, 0.44733393, 0.7682098, 0.674997, 0...</td>\n",
       "      <td>[0.22291431, 0.5704665, 0.0, 0.8096753, 2.1318...</td>\n",
       "      <td>[0.8190571, 1.0594804, 0.11729552, 2.5295827, ...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9185</th>\n",
       "      <td>[0.898952, 0.9875418, 1.0946285, 0.25049916, 1...</td>\n",
       "      <td>[0.7549711, 0.8397508, 0.007906282, 0.6627826,...</td>\n",
       "      <td>[0.78905094, 1.4563938, 0.15960617, 2.9084067,...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9186</th>\n",
       "      <td>[1.1365956, 1.1239127, 1.3068308, 0.9548306, 1...</td>\n",
       "      <td>[0.9241727, 0.90764385, 0.0, 0.79717416, 1.387...</td>\n",
       "      <td>[1.0117414, 1.4901752, 0.04382512, 3.211129, 0...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9187</th>\n",
       "      <td>[1.1158732, 1.4068502, 0.7424753, 0.98150027, ...</td>\n",
       "      <td>[0.4205947, 1.2416991, 0.0, 0.9410689, 1.87923...</td>\n",
       "      <td>[0.7812912, 1.2933567, 0.30341256, 2.6913176, ...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9188</th>\n",
       "      <td>[0.8294226, 1.0668901, 1.6724519, 0.62580425, ...</td>\n",
       "      <td>[0.57063615, 0.8907593, 0.027025366, 0.6214412...</td>\n",
       "      <td>[0.7677369, 1.3293349, 0.25426412, 2.5228605, ...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9189</th>\n",
       "      <td>[0.75481534, 0.85709774, 0.9354368, 0.8150859,...</td>\n",
       "      <td>[0.13983689, 0.6278051, 0.0, 0.75024307, 1.413...</td>\n",
       "      <td>[0.4116444, 1.3898524, 0.18480764, 2.721606, 1...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9190</th>\n",
       "      <td>[0.75500524, 0.8455441, 1.0628494, 0.85174143,...</td>\n",
       "      <td>[0.46766603, 0.57562745, 0.005180718, 0.883754...</td>\n",
       "      <td>[1.0885398, 0.91733575, 0.20453916, 2.5004911,...</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9191</th>\n",
       "      <td>[0.70841265, 0.6843738, 1.3165953, 0.8993471, ...</td>\n",
       "      <td>[0.3661893, 0.6211221, 0.0, 0.78434163, 1.3079...</td>\n",
       "      <td>[0.64220476, 1.3975538, 0.24294741, 2.8046865,...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9192</th>\n",
       "      <td>[0.43090925, 1.1242257, 1.1963427, 0.81024915,...</td>\n",
       "      <td>[0.16440912, 1.2007933, 0.0, 0.88519645, 1.573...</td>\n",
       "      <td>[0.81996185, 1.3216792, 0.18722372, 2.7146792,...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9193</th>\n",
       "      <td>[0.57766485, 1.0219289, 1.3574382, 0.41493505,...</td>\n",
       "      <td>[0.07083293, 0.81113946, 0.0, 0.68737805, 1.23...</td>\n",
       "      <td>[0.5439346, 1.2034178, 0.21905555, 2.3914993, ...</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9194 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  \\\n",
       "0     [1.2266511, 1.0417311, 1.1330203, 0.86150473, ...   \n",
       "1     [0.9260725, 0.5731336, 0.8489482, 0.6313456, 1...   \n",
       "2     [0.8079407, 0.84246206, 0.89299726, 0.6448495,...   \n",
       "3     [0.599945, 1.222887, 1.296843, 1.0004117, 0.99...   \n",
       "4     [0.74703896, 1.3423767, 1.4105116, 0.7901356, ...   \n",
       "5     [0.88963294, 0.5910753, 1.0034066, 1.2651983, ...   \n",
       "6     [0.38441232, 0.567524, 0.6700937, 0.86411256, ...   \n",
       "7     [0.43136236, 0.8914018, 1.1213691, 0.7663166, ...   \n",
       "8     [1.0548836, 0.57110304, 0.57705915, 0.9964003,...   \n",
       "9     [0.62746835, 0.46289912, 0.8168433, 0.6603487,...   \n",
       "10    [1.1941446, 0.9863214, 1.0455906, 0.8168348, 1...   \n",
       "11    [1.4160447, 1.3218861, 0.9660971, 1.33309, 0.7...   \n",
       "12    [1.1593821, 0.7785032, 1.1378238, 0.72918344, ...   \n",
       "13    [0.8249949, 1.2512265, 0.4579049, 1.2566013, 1...   \n",
       "14    [0.35373518, 0.716912, 0.9005486, 1.1021699, 1...   \n",
       "15    [1.1505605, 0.5084761, 1.3164309, 0.54808956, ...   \n",
       "16    [0.47456804, 0.35149944, 0.7526036, 0.51093584...   \n",
       "17    [0.9090706, 0.8371268, 0.9428199, 0.53306776, ...   \n",
       "18    [1.0827852, 1.4389306, 1.431331, 0.77310884, 0...   \n",
       "19    [0.69452995, 1.1959325, 1.3090881, 1.2940817, ...   \n",
       "20    [0.97954327, 0.9856241, 0.67270476, 0.9674342,...   \n",
       "21    [0.8700231, 1.0057819, 0.8614572, 0.99150026, ...   \n",
       "22    [0.92678, 0.7764833, 0.9714116, 0.95193124, 1....   \n",
       "23    [1.0752004, 1.3420398, 1.3904576, 0.7037693, 0...   \n",
       "24    [0.5627111, 0.33239597, 0.9758223, 0.86889356,...   \n",
       "25    [0.42432985, 0.88932836, 0.7727695, 0.698427, ...   \n",
       "26    [0.81034905, 1.1269977, 1.3041121, 0.70037943,...   \n",
       "27    [1.4452187, 0.9991081, 1.871594, 0.50349927, 0...   \n",
       "28    [0.9091235, 1.0322626, 1.0045466, 0.9273859, 0...   \n",
       "29    [0.78108156, 1.1517342, 1.6094176, 0.89147735,...   \n",
       "...                                                 ...   \n",
       "9164  [1.1048782, 0.73922986, 1.5323056, 0.51722085,...   \n",
       "9165  [0.80980843, 0.70740914, 1.1179122, 0.7712648,...   \n",
       "9166  [0.96898997, 1.1219271, 1.4396054, 0.75455433,...   \n",
       "9167  [1.3452278, 1.0870333, 0.95577836, 1.2325946, ...   \n",
       "9168  [0.91805845, 1.1170028, 1.4155775, 0.3886531, ...   \n",
       "9169  [0.5329634, 0.6395203, 1.1510091, 0.8197139, 0...   \n",
       "9170  [1.0443552, 1.3376004, 0.5944006, 0.9581421, 1...   \n",
       "9171  [0.8338877, 1.3742892, 1.2247676, 0.9027906, 1...   \n",
       "9172  [1.3903974, 0.6801297, 1.1442487, 0.72706354, ...   \n",
       "9173  [0.83364034, 0.57737267, 1.5228044, 0.5410602,...   \n",
       "9174  [0.6703258, 0.36793125, 1.0731152, 1.1447587, ...   \n",
       "9175  [0.42263326, 0.8727894, 1.1558088, 0.58081126,...   \n",
       "9176  [0.48774904, 0.75401115, 1.1693717, 0.9749964,...   \n",
       "9177  [0.66593206, 1.0699384, 1.2808576, 0.7722058, ...   \n",
       "9178  [0.98399085, 0.7547867, 1.4024857, 1.0391302, ...   \n",
       "9179  [0.7389063, 1.0877801, 0.7402861, 1.0664952, 1...   \n",
       "9180  [0.677361, 0.53459495, 0.6605791, 1.0548846, 1...   \n",
       "9181  [1.3495919, 1.1840837, 1.316518, 1.3965293, 1....   \n",
       "9182  [1.3185825, 1.4318628, 1.187987, 1.3841957, 1....   \n",
       "9183  [0.8326618, 1.0701257, 1.1290746, 0.6957043, 0...   \n",
       "9184  [0.4731417, 0.44733393, 0.7682098, 0.674997, 0...   \n",
       "9185  [0.898952, 0.9875418, 1.0946285, 0.25049916, 1...   \n",
       "9186  [1.1365956, 1.1239127, 1.3068308, 0.9548306, 1...   \n",
       "9187  [1.1158732, 1.4068502, 0.7424753, 0.98150027, ...   \n",
       "9188  [0.8294226, 1.0668901, 1.6724519, 0.62580425, ...   \n",
       "9189  [0.75481534, 0.85709774, 0.9354368, 0.8150859,...   \n",
       "9190  [0.75500524, 0.8455441, 1.0628494, 0.85174143,...   \n",
       "9191  [0.70841265, 0.6843738, 1.3165953, 0.8993471, ...   \n",
       "9192  [0.43090925, 1.1242257, 1.1963427, 0.81024915,...   \n",
       "9193  [0.57766485, 1.0219289, 1.3574382, 0.41493505,...   \n",
       "\n",
       "                                                      1  \\\n",
       "0     [0.97100186, 0.5840728, 0.018708272, 0.6757692...   \n",
       "1     [0.3021238, 0.57566774, 0.013932347, 0.6377456...   \n",
       "2     [0.6755501, 0.6909119, 0.0015019281, 0.8135175...   \n",
       "3     [0.3050562, 1.0690634, 0.010042003, 0.8362427,...   \n",
       "4     [0.076150075, 1.34196, 0.0, 1.0045176, 1.48474...   \n",
       "5     [0.5554142, 0.5313716, 0.0, 1.3494354, 1.17695...   \n",
       "6     [0.15692724, 0.77687633, 0.0, 0.8505674, 1.627...   \n",
       "7     [0.1252123, 0.75570023, 0.0, 0.7990814, 1.6406...   \n",
       "8     [0.25558898, 0.5446507, 0.0, 0.92947555, 1.051...   \n",
       "9     [0.07032215, 0.5805372, 0.0, 0.7073519, 1.2059...   \n",
       "10    [0.51242816, 0.81379545, 0.0, 0.81825596, 1.34...   \n",
       "11    [0.98665804, 0.91159964, 0.0, 1.0325896, 1.412...   \n",
       "12    [0.78312653, 0.52499694, 0.01604845, 0.9166615...   \n",
       "13    [0.2741711, 1.1039472, 0.0, 1.6175538, 2.04132...   \n",
       "14    [0.13621587, 0.51738465, 0.01489074, 0.8032220...   \n",
       "15    [0.5483058, 0.5331195, 0.0, 0.82636046, 1.2954...   \n",
       "16    [0.41485345, 0.6650646, 0.0, 0.84842837, 2.083...   \n",
       "17    [0.62624407, 0.53010684, 0.027189752, 0.553745...   \n",
       "18    [0.5586376, 1.0527498, 0.0, 0.81319094, 1.4233...   \n",
       "19    [0.087833904, 1.0270096, 0.15224127, 1.3106239...   \n",
       "20    [0.20067716, 0.75440305, 0.0, 0.7237635, 1.248...   \n",
       "21    [0.098198116, 0.76423275, 0.0, 0.8204883, 1.52...   \n",
       "22    [0.7516254, 0.5992485, 0.018889975, 0.51026446...   \n",
       "23    [0.5616659, 1.0250338, 0.0, 0.555512, 1.754320...   \n",
       "24    [0.36074507, 0.5543164, 0.0246257, 0.6868933, ...   \n",
       "25    [0.19513634, 0.7816249, 0.007126488, 0.8655882...   \n",
       "26    [0.5275315, 0.7550219, 0.13558236, 0.64960515,...   \n",
       "27    [1.1188992, 0.79463077, 0.4278977, 0.73458606,...   \n",
       "28    [0.16400178, 0.81292033, 0.0, 0.77544665, 1.28...   \n",
       "29    [0.47887766, 0.6499354, 0.040433116, 0.9524293...   \n",
       "...                                                 ...   \n",
       "9164  [0.6438666, 0.5630163, 0.32229805, 0.64934194,...   \n",
       "9165  [0.18381646, 0.5840082, 0.0, 0.7078125, 1.3878...   \n",
       "9166  [0.6854943, 0.9676646, 0.02073163, 1.036068, 0...   \n",
       "9167  [1.0116054, 0.9115115, 0.0012172187, 0.9337668...   \n",
       "9168  [0.37767714, 0.8120428, 0.0, 0.8491515, 1.2917...   \n",
       "9169  [0.095873885, 0.5097374, 0.0, 0.7565736, 1.211...   \n",
       "9170  [0.24642737, 0.617437, 0.0, 0.9032993, 1.26322...   \n",
       "9171  [0.09795892, 1.0677215, 0.010224995, 0.6444095...   \n",
       "9172  [0.62551713, 0.5096431, 0.0, 0.8055614, 1.1171...   \n",
       "9173  [0.14664185, 0.5826496, 0.35804835, 0.70127815...   \n",
       "9174  [0.36107522, 0.6076762, 0.0, 1.3822148, 1.7078...   \n",
       "9175  [0.069258034, 0.74368405, 0.0, 1.131066, 1.887...   \n",
       "9176  [0.11186211, 0.54658496, 0.0, 0.69178236, 1.10...   \n",
       "9177  [0.21776873, 0.8744145, 0.010778495, 0.4876124...   \n",
       "9178  [0.2671342, 0.7560413, 0.666515, 1.0998068, 1....   \n",
       "9179  [0.21765128, 0.57686234, 0.0, 0.7632327, 1.451...   \n",
       "9180  [0.033634603, 0.42966384, 0.0, 0.8245664, 2.02...   \n",
       "9181  [0.91882664, 0.6032505, 0.01750259, 0.66171956...   \n",
       "9182  [0.90356916, 0.8591377, 0.016486736, 0.671565,...   \n",
       "9183  [0.109357424, 0.9189861, 0.0, 0.8184475, 1.413...   \n",
       "9184  [0.22291431, 0.5704665, 0.0, 0.8096753, 2.1318...   \n",
       "9185  [0.7549711, 0.8397508, 0.007906282, 0.6627826,...   \n",
       "9186  [0.9241727, 0.90764385, 0.0, 0.79717416, 1.387...   \n",
       "9187  [0.4205947, 1.2416991, 0.0, 0.9410689, 1.87923...   \n",
       "9188  [0.57063615, 0.8907593, 0.027025366, 0.6214412...   \n",
       "9189  [0.13983689, 0.6278051, 0.0, 0.75024307, 1.413...   \n",
       "9190  [0.46766603, 0.57562745, 0.005180718, 0.883754...   \n",
       "9191  [0.3661893, 0.6211221, 0.0, 0.78434163, 1.3079...   \n",
       "9192  [0.16440912, 1.2007933, 0.0, 0.88519645, 1.573...   \n",
       "9193  [0.07083293, 0.81113946, 0.0, 0.68737805, 1.23...   \n",
       "\n",
       "                                                      2      3  \n",
       "0     [1.453161, 0.9682333, 0.0762357, 2.2394767, 1....  [1.0]  \n",
       "1     [0.7886908, 1.0985806, 0.19914995, 2.2344904, ...  [1.0]  \n",
       "2     [1.0263835, 1.6801147, 0.12214534, 3.239491, 2...  [1.0]  \n",
       "3     [0.45392486, 1.3208184, 0.04594949, 2.8563154,...  [0.0]  \n",
       "4     [0.33487615, 1.3349226, 0.07892446, 2.7373383,...  [0.0]  \n",
       "5     [0.7941327, 0.9516872, 0.16922458, 2.723517, 1...  [0.0]  \n",
       "6     [0.8577994, 1.0316093, 0.25254643, 2.531352, 1...  [1.0]  \n",
       "7     [0.6947966, 1.0000659, 0.17763479, 2.4569223, ...  [0.0]  \n",
       "8     [0.78453887, 1.2621708, 0.22997604, 2.8855104,...  [0.0]  \n",
       "9     [0.57190776, 1.3017917, 0.2964571, 2.4923735, ...  [0.0]  \n",
       "10    [0.6554679, 1.2440021, 0.28184587, 2.394824, 1...  [1.0]  \n",
       "11    [1.1204507, 1.3650155, 0.20188247, 2.6159732, ...  [1.0]  \n",
       "12    [1.0351921, 1.1763014, 0.06259541, 2.475656, 0...  [1.0]  \n",
       "13    [0.8148253, 1.77486, 0.23513056, 3.1608572, 1....  [0.0]  \n",
       "14    [0.7797959, 1.322388, 0.123931125, 2.4144814, ...  [0.0]  \n",
       "15    [0.63905555, 1.0674386, 0.2660905, 2.745481, 0...  [0.0]  \n",
       "16    [0.7696068, 1.2912567, 0.21132345, 3.0863757, ...  [0.0]  \n",
       "17    [1.0877213, 1.223011, 0.3041957, 2.027799, 2.1...  [0.0]  \n",
       "18    [0.7367632, 1.2793095, 0.20742427, 2.5475137, ...  [1.0]  \n",
       "19    [0.49185985, 1.317891, 0.2634306, 3.4356647, 0...  [1.0]  \n",
       "20    [0.9686982, 1.0572011, 0.30760467, 1.9652164, ...  [1.0]  \n",
       "21    [0.72697943, 1.469209, 0.21518166, 2.7718883, ...  [1.0]  \n",
       "22    [1.1163119, 1.0591897, 0.10162194, 2.3445523, ...  [0.0]  \n",
       "23    [0.34901568, 1.3939581, 0.09273015, 1.5329504,...  [0.0]  \n",
       "24    [0.98933667, 1.3660069, 0.23138268, 2.5460649,...  [0.0]  \n",
       "25    [0.5798936, 1.8104128, 0.110991284, 3.5444713,...  [1.0]  \n",
       "26    [0.70193136, 1.066397, 0.1152596, 2.469129, 2....  [1.0]  \n",
       "27    [1.4008639, 0.90516233, 0.11431219, 1.9774063,...  [0.0]  \n",
       "28    [0.6965086, 0.9007636, 0.24614973, 2.0569568, ...  [0.0]  \n",
       "29    [0.9605986, 1.0693516, 0.23679422, 2.546359, 1...  [0.0]  \n",
       "...                                                 ...    ...  \n",
       "9164  [0.8257044, 1.5426817, 0.4612856, 2.633638, 1....  [1.0]  \n",
       "9165  [0.8567538, 1.3019444, 0.30616665, 2.6546888, ...  [1.0]  \n",
       "9166  [0.81464475, 1.4109824, 0.13531299, 3.1359715,...  [0.0]  \n",
       "9167  [1.0095623, 1.4776814, 0.3107046, 2.8292027, 1...  [0.0]  \n",
       "9168  [0.5913154, 1.49932, 0.18408887, 2.3576136, 1....  [1.0]  \n",
       "9169  [0.59695834, 1.1788837, 0.29237223, 2.1528356,...  [1.0]  \n",
       "9170  [0.71148777, 0.9920536, 0.21719979, 2.3901942,...  [0.0]  \n",
       "9171  [0.2734422, 1.2083552, 0.11518024, 1.985456, 1...  [1.0]  \n",
       "9172  [0.5699313, 0.9061068, 0.25312608, 1.7731636, ...  [1.0]  \n",
       "9173  [0.8640035, 1.0519197, 0.29561996, 2.3006248, ...  [1.0]  \n",
       "9174  [1.1852614, 1.2398369, 0.2702697, 3.190967, 1....  [1.0]  \n",
       "9175  [0.47906446, 1.2162832, 0.20168172, 2.8836854,...  [0.0]  \n",
       "9176  [0.65549016, 0.83333576, 0.35015267, 2.2339704...  [0.0]  \n",
       "9177  [0.3972997, 1.2266059, 0.07659598, 2.3354414, ...  [0.0]  \n",
       "9178  [0.8643138, 1.0525115, 0.5586691, 2.2994623, 1...  [0.0]  \n",
       "9179  [0.5098187, 1.0402429, 0.13221605, 2.6742883, ...  [0.0]  \n",
       "9180  [0.817397, 0.9484475, 0.29730743, 1.9620632, 1...  [0.0]  \n",
       "9181  [1.0389292, 0.97529805, 0.10230906, 2.2153816,...  [0.0]  \n",
       "9182  [1.059758, 0.942966, 0.089776084, 2.2550201, 1...  [0.0]  \n",
       "9183  [0.88998353, 1.1392044, 0.29695988, 2.4473202,...  [1.0]  \n",
       "9184  [0.8190571, 1.0594804, 0.11729552, 2.5295827, ...  [1.0]  \n",
       "9185  [0.78905094, 1.4563938, 0.15960617, 2.9084067,...  [1.0]  \n",
       "9186  [1.0117414, 1.4901752, 0.04382512, 3.211129, 0...  [0.0]  \n",
       "9187  [0.7812912, 1.2933567, 0.30341256, 2.6913176, ...  [0.0]  \n",
       "9188  [0.7677369, 1.3293349, 0.25426412, 2.5228605, ...  [1.0]  \n",
       "9189  [0.4116444, 1.3898524, 0.18480764, 2.721606, 1...  [1.0]  \n",
       "9190  [1.0885398, 0.91733575, 0.20453916, 2.5004911,...  [0.0]  \n",
       "9191  [0.64220476, 1.3975538, 0.24294741, 2.8046865,...  [1.0]  \n",
       "9192  [0.81996185, 1.3216792, 0.18722372, 2.7146792,...  [1.0]  \n",
       "9193  [0.5439346, 1.2034178, 0.21905555, 2.3914993, ...  [1.0]  \n",
       "\n",
       "[9194 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[train_set.columns[3]] = train_set[train_set.columns[3]].apply(lambda x: np.array(x))\n",
    "train_set[train_set.columns[0]] = train_set[train_set.columns[0]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "train_set[train_set.columns[1]] = train_set[train_set.columns[1]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "train_set[train_set.columns[2]] = train_set[train_set.columns[2]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "\n",
    "test_set[test_set.columns[3]] = test_set[test_set.columns[3]].apply(lambda x: np.array(x))\n",
    "test_set[test_set.columns[0]] = test_set[test_set.columns[0]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "test_set[test_set.columns[1]] = test_set[test_set.columns[1]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "test_set[test_set.columns[2]] = test_set[test_set.columns[2]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "\n",
    "val_set[val_set.columns[3]] = val_set[val_set.columns[3]].apply(lambda x: np.array(x))\n",
    "val_set[val_set.columns[0]] = val_set[val_set.columns[0]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "val_set[val_set.columns[1]] = val_set[val_set.columns[1]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "val_set[val_set.columns[2]] = val_set[val_set.columns[2]].apply(lambda x: x.reshape((x.shape[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(X,y, X_test, y_test, X_val, y_val):\n",
    "    X_clean = []\n",
    "    for row in X:\n",
    "        X_clean.append(row.tolist())\n",
    "    X = X_clean\n",
    "    \n",
    "    X_test_clean = []\n",
    "    for row in X_test:\n",
    "        X_test_clean.append(row.tolist())\n",
    "    X_test = X_test_clean\n",
    "    \n",
    "    X_val_clean = []\n",
    "    for row in X_val:\n",
    "        X_val_clean.append(row.tolist())\n",
    "    X_val = X_val_clean\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    scaler.fit(X_test)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    scaler.fit(X_val)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    \n",
    "    y=y.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "    y_val=y_val.astype('int')\n",
    "    return X,y,X_test,y_test, X_val, y_val\n",
    "\n",
    "X_3, y_3, X_test_3, y_test_3, X_val_3, y_val_3 = prep_data(np.array(train_set[train_set.columns[0]]),\n",
    "                                        np.array(train_set[train_set.columns[3]]),\n",
    "                                        np.array(test_set[test_set.columns[0]]),\n",
    "                                        np.array(test_set[test_set.columns[3]]),\n",
    "                                        np.array(val_set[val_set.columns[0]]),\n",
    "                                        np.array(val_set[val_set.columns[3]]))\n",
    "\n",
    "X_2, y_2, X_test_2, y_test_2, X_val_2, y_val_2 = prep_data(np.array(train_set[train_set.columns[1]]),\n",
    "                                        np.array(train_set[train_set.columns[3]]),\n",
    "                                        np.array(test_set[test_set.columns[1]]),\n",
    "                                        np.array(test_set[test_set.columns[3]]),\n",
    "                                        np.array(val_set[val_set.columns[1]]),\n",
    "                                        np.array(val_set[val_set.columns[3]]))\n",
    "\n",
    "\n",
    "X_1, y_1, X_test_1, y_test_1, X_val_1, y_val_1 = prep_data(np.array(train_set[train_set.columns[2]]),\n",
    "                                        np.array(train_set[train_set.columns[3]]),\n",
    "                                        np.array(test_set[test_set.columns[2]]),\n",
    "                                        np.array(test_set[test_set.columns[3]]),\n",
    "                                        np.array(val_set[val_set.columns[2]]),\n",
    "                                        np.array(val_set[val_set.columns[3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olafkroon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN 0.683597998694801\n",
      "VAL 0.6223628691983122\n"
     ]
    }
   ],
   "source": [
    "clf_3 = LogisticRegression(C = 0.01)\n",
    "\n",
    "print(\"third layer\")\n",
    "clf_3.fit(X_3, y_3)\n",
    "train_score = clf_3.score(X_3, y_3)\n",
    "val_score = clf_3.score(X_val_3, y_val_3)\n",
    "print(\"TRAIN\", train_score)\n",
    "print(\"VAL\", val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 0.5829596412556054\n"
     ]
    }
   ],
   "source": [
    "test_score = clf_3.score(X_test_3, y_test_3)\n",
    "print(\"TEST\",test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olafkroon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN 0.6717424407222101\n",
      "VAL 0.5759493670886076\n"
     ]
    }
   ],
   "source": [
    "clf_2 = LogisticRegression(C = 0.01)\n",
    "\n",
    "print(\"second layer\")\n",
    "clf_2.fit(X_2, y_3)\n",
    "train_score = clf_2.score(X_2, y_2)\n",
    "val_score = clf_2.score(X_val_2, y_val_2)\n",
    "print(\"TRAIN\", train_score)\n",
    "print(\"VAL\",  val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5928251121076233\n"
     ]
    }
   ],
   "source": [
    "test_score = clf_2.score(X_test_2, y_test_2)\n",
    "print(test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olafkroon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN 0.6540134870567762\n",
      "VAL 0.5970464135021097\n"
     ]
    }
   ],
   "source": [
    "clf_1 = LogisticRegression(C = 0.01)\n",
    "print('first layer')\n",
    "clf_1.fit(X_1, y_1)\n",
    "train_score = clf_1.score(X_1, y_1)\n",
    "val_score = clf_1.score(X_val_1, y_val_1)\n",
    "print(\"TRAIN\", train_score)\n",
    "print(\"VAL\",  val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 0.6\n"
     ]
    }
   ],
   "source": [
    "test_score = clf_1.score(X_test_1, y_test_1)\n",
    "print(\"TEST\",test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
