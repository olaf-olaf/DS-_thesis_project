{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_pickle('all features/resnet-img/resnet_imagenet_train.pl')\n",
    "test_set = pd.read_pickle('all features/resnet-img/resnet_imagenet_test.pl')\n",
    "val_set = pd.read_pickle('all features/resnet-img/resnet_imagenet_val.pl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[train_set.columns[3]] = train_set[train_set.columns[3]].apply(lambda x: np.array(x))\n",
    "train_set[train_set.columns[0]] = train_set[train_set.columns[0]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "train_set[train_set.columns[1]] = train_set[train_set.columns[1]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "train_set[train_set.columns[2]] = train_set[train_set.columns[2]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "\n",
    "test_set[test_set.columns[3]] = test_set[test_set.columns[3]].apply(lambda x: np.array(x))\n",
    "test_set[test_set.columns[0]] = test_set[test_set.columns[0]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "test_set[test_set.columns[1]] = test_set[test_set.columns[1]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "test_set[test_set.columns[2]] = test_set[test_set.columns[2]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "\n",
    "val_set[val_set.columns[3]] = val_set[val_set.columns[3]].apply(lambda x: np.array(x))\n",
    "val_set[val_set.columns[0]] = val_set[val_set.columns[0]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "val_set[val_set.columns[1]] = val_set[val_set.columns[1]].apply(lambda x: x.reshape((x.shape[1])))\n",
    "val_set[val_set.columns[2]] = val_set[val_set.columns[2]].apply(lambda x: x.reshape((x.shape[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(X,y, X_test, y_test, X_val, y_val):\n",
    "    X_clean = []\n",
    "    for row in X:\n",
    "        X_clean.append(row.tolist())\n",
    "    X = X_clean\n",
    "    \n",
    "    X_test_clean = []\n",
    "    for row in X_test:\n",
    "        X_test_clean.append(row.tolist())\n",
    "    X_test = X_test_clean\n",
    "    \n",
    "    X_val_clean = []\n",
    "    for row in X_val:\n",
    "        X_val_clean.append(row.tolist())\n",
    "    X_val = X_val_clean\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    scaler.fit(X_test)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    scaler.fit(X_val)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    \n",
    "    y=y.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "    y_val=y_val.astype('int')\n",
    "    return X,y,X_test,y_test, X_val, y_val\n",
    "\n",
    "X_3, y_3, X_test_3, y_test_3, X_val_3, y_val_3 = prep_data(np.array(train_set[train_set.columns[0]]),\n",
    "                                        np.array(train_set[train_set.columns[3]]),\n",
    "                                        np.array(test_set[test_set.columns[0]]),\n",
    "                                        np.array(test_set[test_set.columns[3]]),\n",
    "                                        np.array(val_set[val_set.columns[0]]),\n",
    "                                        np.array(val_set[val_set.columns[3]]))\n",
    "\n",
    "X_2, y_2, X_test_2, y_test_2, X_val_2, y_val_2 = prep_data(np.array(train_set[train_set.columns[1]]),\n",
    "                                        np.array(train_set[train_set.columns[3]]),\n",
    "                                        np.array(test_set[test_set.columns[1]]),\n",
    "                                        np.array(test_set[test_set.columns[3]]),\n",
    "                                        np.array(val_set[val_set.columns[1]]),\n",
    "                                        np.array(val_set[val_set.columns[3]]))\n",
    "\n",
    "\n",
    "X_1, y_1, X_test_1, y_test_1, X_val_1, y_val_1 = prep_data(np.array(train_set[train_set.columns[2]]),\n",
    "                                        np.array(train_set[train_set.columns[3]]),\n",
    "                                        np.array(test_set[test_set.columns[2]]),\n",
    "                                        np.array(test_set[test_set.columns[3]]),\n",
    "                                        np.array(val_set[val_set.columns[2]]),\n",
    "                                        np.array(val_set[val_set.columns[3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olafkroon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN 0.6332390689580161\n",
      "VAL 0.6518987341772152\n"
     ]
    }
   ],
   "source": [
    "clf_3 = LogisticRegression(C = 0.01)\n",
    "\n",
    "print(\"third layer\")\n",
    "clf_3.fit(X_3, y_3)\n",
    "train_score = clf_3.score(X_3, y_3)\n",
    "val_score = clf_3.score(X_val_3, y_val_3)\n",
    "print(\"TRAIN\", train_score)\n",
    "print(\"VAL\", val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 0.610762331838565\n"
     ]
    }
   ],
   "source": [
    "test_score = clf_3.score(X_test_3, y_test_3)\n",
    "print(\"TEST\",test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olafkroon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN 0.6717424407222101\n",
      "VAL 0.6455696202531646\n"
     ]
    }
   ],
   "source": [
    "clf_2 = LogisticRegression(C = 0.01)\n",
    "\n",
    "print(\"second layer\")\n",
    "clf_2.fit(X_2, y_3)\n",
    "train_score = clf_2.score(X_2, y_2)\n",
    "val_score = clf_2.score(X_val_2, y_val_2)\n",
    "print(\"TRAIN\", train_score)\n",
    "print(\"VAL\",  val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6260089686098654\n"
     ]
    }
   ],
   "source": [
    "test_score = clf_2.score(X_test_2, y_test_2)\n",
    "print(test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olafkroon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN 0.6790298020448118\n",
      "VAL 0.5970464135021097\n"
     ]
    }
   ],
   "source": [
    "clf_1 = LogisticRegression(C = 0.01)\n",
    "print('first layer')\n",
    "clf_1.fit(X_1, y_1)\n",
    "train_score = clf_1.score(X_1, y_1)\n",
    "val_score = clf_1.score(X_val_1, y_val_1)\n",
    "print(\"TRAIN\", train_score)\n",
    "print(\"VAL\",  val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 0.6170403587443947\n"
     ]
    }
   ],
   "source": [
    "test_score = clf_1.score(X_test_1, y_test_1)\n",
    "print(\"TEST\",test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
